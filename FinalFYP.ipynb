{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kiran Reddy\n",
    "#### CM3070 Final Year Project "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction \n",
    "\n",
    "This is my Final Year Project Prototype for the endterm of the CM3070 module. Throughout this project, \n",
    "I have followed the universal Machine Learning workflow. \n",
    "\n",
    "The dataset used is the MBTI (Multi Briggs Personality Type Dataset) from Kaggle. The Myers-Briggs Person Dataset categorises an individual into one of the 16 different types across 4 main axes. Figure 1 is an example image on how the dataset looks like. There are in total 16 different personalities among the four different axes. \n",
    "\n",
    "The main motivation to take on this topic is that the use of social media has become extremely prevalent in today's society, and top companies have leveraged on the power of ML and AI to use data acquired from various platforms to improve their business. \n",
    "\n",
    "I am using the template based on CM3015 Machine Learning and Neural Networks template. It will follow machine learning with deep learning from a public dataset template.\n",
    "\n",
    "###### 1. Stating the problem statement and gathering a dataset\n",
    "\n",
    "The problem in this project is to accruately categorise each of the last 50 things they have posted into 16 different personality types across 4 different axis. (Introversion, Intuition, Thinking, Jugding). This dataset contains 86000 rows of data and two columns, the type and texts. \n",
    "\n",
    "###### 2. Choosing a measure of success \n",
    "\n",
    "The measure of success in this project will be the accuracy at the end. In other words, the more accurate the model can classify the images in the correct category, the more successful this project is. I have first started the implementation of the project by doing some pre processing and then splitting the dataset into the standard 60-40 ratio. After which I have implemented 4 different models and compared each of their accuracies. \n",
    "\n",
    "Again after that, I prepared the data this time with a 70-30 ratio and also implemented the models. This time the models show a much better result. After this, I also implement the hyper parameter training on the dataset. \n",
    "\n",
    "###### 3. Deciding on the evaluation protocole\n",
    "\n",
    "The evaluation protocol that I chose is by maintaining a hold-out validation (train, test) set which is the way to go when there is plenty of data. First I follow the 60-40 and then the 70-30 ratio dataset. While training the models, I made sure to train them seperately for each MBTI personality type, to get better results. \n",
    "\n",
    "###### 4. Preparing the data\n",
    "\n",
    "In order to prepare my data, I will need to format my data by removing multiple punctuation, non words, stripping of punctuation, removing links and converting all the posts to lower case. \n",
    "\n",
    "Pre - Processing Steps:\n",
    "Removing of links\n",
    "I do this by using the lambda function and reading if there are any lines of code containing the https,?,,/,etc. If there are, I would simply replace them by spaces\n",
    "\n",
    "Remaining the end of sentence characters such as the '?', '/','' Again I do this by reading through the texts to see if any of these characters are present.\n",
    "\n",
    "Removal of fullstops I read through the texts to see if any of the fullstops are present and will remove it to enable more accurate results and fullstops or non prominent words wont add to the training and testing of my data.\n",
    "\n",
    "Removal of non words\n",
    "\n",
    "Converting the texts to all lowercase This is to better read and train the dataset to enable more accurate results\n",
    "Similarly removal of too short or too long words. I find that these words dont add too much of a value and are redundant and thus have removed words which are maximum of 3 letters and words that are in between 30 - 1000 letters.\n",
    "\n",
    "Removing the personality words in the texts This is because if these words are in the texts, then it would influence the prediction and may interfere with the model\n",
    "\n",
    "###### 5. Developing a model \n",
    "\n",
    "Three points that I kept in my mind while developing the model was, the last-layer activation, loss function, and the optimization configuration. The last layer activation is to make sure the the constraints on the output of the previous layer. The loss function will define the feedback signal used for learning. And lastly, the optimization configuration which determines how learning proceeds, based on the loss function. After running through the models and implementing them seperately for the 60-40 ration and 70-30 ratio, I also implemented the hyperparameter training on the model to get better results but only managed to improve the results of one particular personality type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /Users/Kiranreddy/opt/anaconda3/lib/python3.8/site-packages (1.6.1)\n",
      "Requirement already satisfied: scipy in /Users/Kiranreddy/opt/anaconda3/lib/python3.8/site-packages (from xgboost) (1.5.2)\n",
      "Requirement already satisfied: numpy in /Users/Kiranreddy/opt/anaconda3/lib/python3.8/site-packages (from xgboost) (1.22.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the relevant libraries consiting of data analytics, data visualization, text processing, training and evaluations model\n",
    "\n",
    "Note: These libraries have not been installed in order because I added in new lines of codes in between the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "import pickle as pkl\n",
    "from scipy import sparse\n",
    "import re\n",
    "import seaborn as sns\n",
    "import wordcloud\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from numpy import loadtxt\n",
    "from numpy import savetxt\n",
    "import itertools\n",
    "import string\n",
    "import collections\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from xgboost import XGBClassifier\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.cluster as cluster\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, accuracy_score, balanced_accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, multilabel_confusion_matrix, confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importing the dataset, link to the datatset: https://www.kaggle.com/datasnaek/mbti-type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8670</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>'https://www.youtube.com/watch?v=t8edHB_h908||...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8671</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>'So...if this thread already exists someplace ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8672</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'So many questions when i do these things.  I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8673</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'I am very conflicted right now when it comes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8674</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'It has been too long since I have been on per...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                              posts\n",
       "8670  ISFP  'https://www.youtube.com/watch?v=t8edHB_h908||...\n",
       "8671  ENFP  'So...if this thread already exists someplace ...\n",
       "8672  INTP  'So many questions when i do these things.  I ...\n",
       "8673  INFP  'I am very conflicted right now when it comes ...\n",
       "8674  INFP  'It has been too long since I have been on per..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading dataset\n",
    "mydata = pd.read_csv(\"/Users/Kiranreddy/Desktop/FYP/mbti.csv\")\n",
    "\n",
    "# Going to show the last few lines of my dataset, basically the last 5 records of the csv files\n",
    "mydata.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre Processing of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In order to prepare my data, I will need to format my data by removing multiple punctuation, non words, stripping of punctuation, removing links and converting all the posts to lower case. \n",
    "\n",
    "Pre - Processing Steps: \n",
    "\n",
    "1. Removing of links \n",
    "\n",
    "I do this by using the lambda function and reading if there are any lines of code containing the https,?,\\,/,etc.\n",
    "If there are, I would simply replace them by spaces/ \n",
    "\n",
    "2. Remaining the end of sentence characters such as the '?', '/','\\'\n",
    "Again I do this by reading through the texts to see if any of these characters are present. \n",
    "\n",
    "3. Removal of fullstops \n",
    "I read through the texts to see if any of the fullstops are present and will remove it to enable more accurate results and fullstops or non prominent words wont add to the training and testing of my data. \n",
    "\n",
    "4. Removal of non words \n",
    "\n",
    "5. Converting the texts to all lowercase \n",
    "This is to better read and train the dataset to enable more accurate results \n",
    "\n",
    "6. Similarly removal of too short or too long words. \n",
    "I find that these words dont add too much of a value and are redundant and thus have removed words which are maximum of 3 letters and words that are in between 30 - 1000 letters. \n",
    "\n",
    "7. Removing the personality words in the texts \n",
    "This is because if these words are in the texts, then it would influence the prediction and may interfere with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_method(df, remove_special=True):\n",
    "    posts = df['posts'].copy()\n",
    "    labels_type = df['type'].copy()\n",
    "\n",
    "   \n",
    "    df[\"posts\"] = df[\"posts\"].apply(lambda x: re.sub(r'[^\\w\\s]','',x))\n",
    "    df[\"posts\"] = df[\"posts\"].apply(lambda x: re.sub(r'https?:\\/\\/.*?[\\s+]', '', x.replace(\"|\",\" \") + \" \"))\n",
    "    df[\"posts\"] = df[\"posts\"].apply(lambda x: re.sub(r'!', ' EOSTokenExs ', x + \" \"))\n",
    "    df[\"posts\"] = df[\"posts\"].apply(lambda x: re.sub(r'\\?', ' EOSTokenQuest ', x + \" \"))\n",
    "    if remove_special:\n",
    "        pers_types = ['INFP' ,'INFJ', 'INTP', 'INTJ', 'ENTP', 'ENFP', 'ISTP' ,'ISFP' ,'ENTJ', 'ISTJ','ENFJ', 'ISFJ' ,'ESTP', 'ESFP' ,'ESFJ' ,'ESTJ']\n",
    "        pers_types = [p.lower() for p in pers_types]\n",
    "        p = re.compile(\"(\" + \"|\".join(pers_types) + \")\")\n",
    "    df[\"posts\"] = df[\"posts\"].apply(lambda x: re.sub(r'[\\.+]', \".\",x))\n",
    "    df[\"posts\"] = df[\"posts\"].apply(lambda x: x.lower())\n",
    "    df[\"posts\"] = df[\"posts\"].apply(lambda x: re.sub(r'\\.', ' EOSTokenDot ', x + \" \"))\n",
    "    df[\"posts\"] = df[\"posts\"].apply(lambda x: re.sub(r'[^a-zA-Z\\s]','',x)) \n",
    "    df[\"posts\"] = df[\"posts\"].apply(lambda x: re.sub(r'(\\b\\w{30,1000})?\\b','',x))\n",
    "    df[\"posts\"] = df[\"posts\"].apply(lambda x: re.sub(r'([a-z])\\1{2,}[\\s|\\w]*','',x))\n",
    "    df[\"posts\"] = df[\"posts\"].apply(lambda x: re.sub(r'(\\b\\w{0,3})?\\b','',x))\n",
    "    \n",
    "    return df\n",
    "\n",
    "preprocess_df = preprocess_method(mydata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialising the minimum words to be 16 and removing other texts that have less than 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Posts in dataset before:  8675\n",
      "Number of Posts in dataset after:  8426\n"
     ]
    }
   ],
   "source": [
    "minimum_words = 16\n",
    "print(\"Number of Posts in dataset before: \", len(preprocess_df)) \n",
    "preprocess_df[\"number words\"] = preprocess_df[\"posts\"].apply(lambda x: len(re.findall(r'\\w+', x)))\n",
    "preprocess_df = preprocess_df[preprocess_df[\"number words\"] >= minimum_words]\n",
    "\n",
    "print(\"Number of Posts in dataset after: \", len(preprocess_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As you can see, we have removed over 200 texts that have texts less than 16 words. Now we will be working with this new dataset after pre process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>number words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>intj moments    sportscenter    plays    pra...</td>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>finding  lack    these posts very alarmingsex...</td>\n",
       "      <td>626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>good       course  which    know thats  blessi...</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>dear intp    enjoyed  conversation  other   es...</td>\n",
       "      <td>603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>youre firedthats another silly misconception t...</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts  number words\n",
       "0  INFJ    intj moments    sportscenter    plays    pra...           329\n",
       "1  ENTP   finding  lack    these posts very alarmingsex...           626\n",
       "2  INTP  good       course  which    know thats  blessi...           209\n",
       "3  INTJ  dear intp    enjoyed  conversation  other   es...           603\n",
       "4  ENTJ  youre firedthats another silly misconception t...           312"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforming the MBTI personality types for the target values into numerical form usinig the labelEncoder function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "preprocess_df['Encoding Type'] = encoder.fit_transform(preprocess_df['type'])\n",
    "\n",
    "targetY = preprocess_df['Encoding Type'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Similarly transforming the MBTI personality types for the train values into numerical form usinig the Vectorizer function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english') \n",
    "trainX =  vectorizer.fit_transform(preprocess_df[\"posts\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the training and test dataset into 60 - 40 ratio to see how the accuracies are for the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5055, 229133) (5055,) (3371, 229133) (3371,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(trainX, targetY, test_size=0.4, stratify=targetY, random_state=41)\n",
    "print ((X_train.shape),(y_train.shape),(X_test.shape),(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8426, 229133)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8426,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targetY.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting to run my models on the dataset to see the accuriacies acheieved by each of them. \n",
    "\n",
    "The different models I will be using will be: \n",
    "    \n",
    "     - KNN Classifier\n",
    "     - Logisitic Regression\n",
    "     - XG Boost \n",
    "     - SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining an array named accuracy_array so that this will help me to output when I compare the different models and I can store the different accuracies in this array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_array = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Model Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 16.14%\n"
     ]
    }
   ],
   "source": [
    "# Using K value as 2 here \n",
    "\n",
    "modelknn = KNeighborsClassifier(n_neighbors = 2) \n",
    "modelknn.fit(X_train, y_train)\n",
    "\n",
    "Y_results = modelknn.predict(X_test)\n",
    "predic = [round(value) for value in Y_results]\n",
    "\n",
    "# These will be the predictions by the KNN model\n",
    "accuracy_value = accuracy_score(y_test, predic)\n",
    "# Also storing the value of accuracy into the array\n",
    "accuracy_array['KNN Model'] = accuracy_value* 100.0\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy_value * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Result for KNN is 24.83%\n"
     ]
    }
   ],
   "source": [
    "## This is for me to find the best value of K here, to improve the accuracy results\n",
    "KValueList = []\n",
    "# Between a value of 1 - 19, checking which gives the best result\n",
    "\n",
    "ListOfScores = []\n",
    "for j in range(1,19):\n",
    "    knnModelTest = KNeighborsClassifier(n_neighbors = j) \n",
    "    knnModelTest.fit(X_train, y_train)\n",
    "    KValueList.append(knnModelTest.score(X_test, y_test))\n",
    "\n",
    "best_score = max(KValueList)*100\n",
    "\n",
    "print(\"Best Result for KNN is {:.2f}%\".format(best_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9992087042532146\n",
      "Accuracy: 53.90%\n"
     ]
    }
   ],
   "source": [
    "modelXGB = XGBClassifier()\n",
    "modelXGB.fit(X_train,y_train)\n",
    "\n",
    "Y_pred = modelXGB.predict(X_test)\n",
    "predic = [round(value) for value in Y_pred]\n",
    "\n",
    "# These will be the predictions by the mode\n",
    "accuracy_value = accuracy_score(y_test, predic)\n",
    "# Also storing the value of accuracy into the array\n",
    "accuracy_array['XG Boost Model'] = accuracy_value* 100.0\n",
    "print(accuracy_score(y_train, modelXGB.predict(X_train)))\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy_value * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 50.76%\n"
     ]
    }
   ],
   "source": [
    "logisregress = LogisticRegression()\n",
    "logisregress.fit(X_train, y_train)\n",
    "\n",
    "Y_predict = logisregress.predict(X_test)\n",
    "predic = [round(value) for value in Y_predict] \n",
    "\n",
    "\n",
    "# These will be the predictions by the mode\n",
    "accuracy_value = accuracy_score(y_test, predic)\n",
    "# Also storing the value of accuracy into the array\n",
    "accuracy_array['Logistic Regression Model'] = accuracy_value* 100.0\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy_value * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 48.47%\n"
     ]
    }
   ],
   "source": [
    "ModelSVM = SVC(random_state = 1)\n",
    "ModelSVM.fit(X_train, y_train)\n",
    "\n",
    "predictY = ModelSVM.predict(X_test)\n",
    "\n",
    "predic = [round(value) for value in predictY]\n",
    "# These will be the predictions by the mode\n",
    "accuracy_value = accuracy_score(y_test, predic)\n",
    "# Also storing the value of accuracy into the array\n",
    "accuracy_array['SVM Model'] = accuracy_value* 100.0\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy_value * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy in %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNN Model</th>\n",
       "      <td>16.137645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XG Boost Model</th>\n",
       "      <td>53.900920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression Model</th>\n",
       "      <td>50.756452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM Model</th>\n",
       "      <td>48.472263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Accuracy in %\n",
       "KNN Model                      16.137645\n",
       "XG Boost Model                 53.900920\n",
       "Logistic Regression Model      50.756452\n",
       "SVM Model                      48.472263"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(accuracy_array, orient='index', columns=['Accuracy in %'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the training and test dataset into 70 - 30 ratio to see how the accuracies are for the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5645, 229133) (5645,) (2781, 229133) (2781,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(trainX, targetY, test_size=0.33, stratify=targetY, random_state=42)\n",
    "print ((X_train.shape),(y_train.shape),(X_test.shape),(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 15.82%\n"
     ]
    }
   ],
   "source": [
    "# Using K value as 2 here \n",
    "ModelKNN = KNeighborsClassifier(n_neighbors = 2) \n",
    "ModelKNN.fit(X_train, y_train)\n",
    "\n",
    "predictY = ModelKNN.predict(X_test)\n",
    "predic = [round(value) for value in predictY]\n",
    "\n",
    "# These will be the predictions by the mode\n",
    "accuracy_value = accuracy_score(y_test, predic)\n",
    "# Also storing the value of accuracy into the array\n",
    "accuracy_array['KNN Model'] = accuracy_value* 100.0\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy_value * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Result for KNN is 23.12%\n"
     ]
    }
   ],
   "source": [
    "# This is for me to find the best value of K here, to improve the accuracy results\n",
    "KValueList = []\n",
    "# Between a value of 1 - 19, checking which gives the best result\n",
    "\n",
    "for j in range(1,19):\n",
    "    knnModelTest = KNeighborsClassifier(n_neighbors = j) \n",
    "    knnModelTest.fit(X_train, y_train)\n",
    "    KValueList.append(knnModelTest.score(X_test, y_test))\n",
    "    \n",
    "\n",
    "best_result = max(KValueList)*100\n",
    "\n",
    "print(\"Best Result for KNN is {:.2f}%\".format(best_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9969884853852967\n",
      "Accuracy: 56.02%\n"
     ]
    }
   ],
   "source": [
    "modelXGB = XGBClassifier()\n",
    "modelXGB.fit(X_train,y_train)\n",
    "\n",
    "Y_pred = modelXGB.predict(X_test)\n",
    "predic = [round(value) for value in Y_pred]\n",
    "\n",
    "# These will be the predictions by the mode\n",
    "accuracy_value = accuracy_score(y_test, predic)\n",
    "# Also storing the value of accuracy into the array\n",
    "accuracy_array['XG Boost Model'] = accuracy_value* 100.0\n",
    "print(accuracy_score(y_train, modelXGB.predict(X_train)))\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy_value * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 49.62%\n"
     ]
    }
   ],
   "source": [
    "ModelSVM = SVC(random_state = 1)\n",
    "ModelSVM.fit(X_train, y_train)\n",
    "\n",
    "predictY = ModelSVM.predict(X_test)\n",
    "\n",
    "predic = [round(value) for value in predictY]\n",
    "# These will be the predictions by the mode\n",
    "accuracy_value = accuracy_score(y_test, predic)\n",
    "# Also storing the value of accuracy into the array\n",
    "accuracy_array['SVM Model'] = accuracy_value* 100.0\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy_value * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 50.49%\n"
     ]
    }
   ],
   "source": [
    "logisregress = LogisticRegression()\n",
    "logisregress.fit(X_train, y_train)\n",
    "\n",
    "Y_predict = logisregress.predict(X_test)\n",
    "predic = [round(value) for value in Y_predict]\n",
    "\n",
    "\n",
    "# These will be the predictions by the mode\n",
    "accuracy_value = accuracy_score(y_test, predic)\n",
    "# Also storing the value of accuracy into the array\n",
    "accuracy_array['Logistic Regression Model'] = accuracy_value* 100.0\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy_value * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy in %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNN Model</th>\n",
       "      <td>15.821647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XG Boost Model</th>\n",
       "      <td>56.023013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression Model</th>\n",
       "      <td>50.485437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM Model</th>\n",
       "      <td>49.622438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Accuracy in %\n",
       "KNN Model                      15.821647\n",
       "XG Boost Model                 56.023013\n",
       "Logistic Regression Model      50.485437\n",
       "SVM Model                      49.622438"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(accuracy_array, orient='index', columns=['Accuracy in %'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8670</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>'https://www.youtube.com/watch?v=t8edHB_h908||...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8671</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>'So...if this thread already exists someplace ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8672</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'So many questions when i do these things.  I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8673</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'I am very conflicted right now when it comes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8674</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'It has been too long since I have been on per...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                              posts\n",
       "8670  ISFP  'https://www.youtube.com/watch?v=t8edHB_h908||...\n",
       "8671  ENFP  'So...if this thread already exists someplace ...\n",
       "8672  INTP  'So many questions when i do these things.  I ...\n",
       "8673  INFP  'I am very conflicted right now when it comes ...\n",
       "8674  INFP  'It has been too long since I have been on per..."
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata = pd.read_csv(\"/Users/Kiranreddy/Desktop/FYP/mbti.csv\")\n",
    "mydata.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 2 - Using just the four axes instead of all the 16 personality groups as it gave me very low accuracy results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmat = WordNetLemmatizer()\n",
    "# I am removing all the stop words that are in English\n",
    "stop_words = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removal of the personality type words from the texts and equating it to an array called MBTI array\n",
    "MBTI_array = ['INFJ', 'ENTP','ESTP', 'INTP','ISFP', 'ISTP', 'ISFJ', 'ISTJ','ESFP',\n",
    "              'INTJ', 'ESTJ','ENTJ', 'ENFJ', 'INFP', 'ENFP', 'ESFJ']\n",
    "MBTI_array = [y.lower() for y in MBTI_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binarized Version \n",
      "[[0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Making the MBTI personality types into a numerical form, for example I = 0 and E = 1\n",
    "\n",
    "personality_numerical = {'F':0,'N':0, 'J':0,'T':1,'S':1, 'I':0,'P':1,'E':1,}\n",
    "personality_numerical_list = [{0:'J', 1:'P'},{0:'F', 1:'T'},{0:'I', 1:'E'}, {0:'N', 1:'S'}]\n",
    "\n",
    "# converting the personality types of MBTI into Binary \n",
    "def convert(personality):\n",
    "    return [personality_numerical[y] for y in personality]\n",
    "\n",
    "\n",
    "#Reverse conversion from binary\n",
    "def convertBack(personality):\n",
    "    m = \"\"\n",
    "    for i, y in enumerate(personality):\n",
    "        m += personality_numerical_list[i][y]\n",
    "    return m\n",
    "\n",
    "listBinary_personality = np.array([convert(p) for p in mydata.type])\n",
    "print(\"Binarized Version \\n%s\" % listBinary_personality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(data, remove_stop_words=True, remove_mbti_profiles=True):\n",
    "  personalityList = []\n",
    "  textsList = []\n",
    "  dataLength = len(data)\n",
    "  j=0\n",
    "  \n",
    "  for entry in data.iterrows():\n",
    "        \n",
    "\n",
    "      texts = entry[1].posts\n",
    "        \n",
    "      garb = re.sub(\"[^a-zA-Z]\", \" \", texts)\n",
    "      garb = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' ', texts)\n",
    "      garb = re.sub(' +', ' ', texts).lower()\n",
    "      garb = re.sub(r'([a-z])\\1{2,}[\\s|\\w]*', '', texts)\n",
    "      if remove_stop_words:\n",
    "          garb = \" \".join([lemmat.lemmatize(y) for y in garb.split(' ') if y not in stop_words])\n",
    "      else:\n",
    "          garb = \" \".join([lemmat.lemmatize(y) for y in garb.split(' ')])\n",
    "          \n",
    "      #Remove MBTI personality words from posts\n",
    "      if remove_mbti_profiles:\n",
    "          for t in MBTI_array:\n",
    "              garb = garb.replace(t,\"\")\n",
    "\n",
    "      # transform mbti to binary vector\n",
    "      type_labelized = convert(entry[1].type)\n",
    "      personalityList.append(type_labelized)\n",
    "      textsList.append(garb)\n",
    "    \n",
    "  textsList = np.array(textsList)\n",
    "  personalityList = np.array(personalityList)\n",
    "  return textsList, personalityList\n",
    "\n",
    "textsList, personalityList  = text_preprocessing(mydata, remove_stop_words=True, remove_mbti_profiles=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Printing the number of columns and rows of the dataset, outputting the number of texts and number of personality groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of texts = 8675  and Personality Groups = 4 \n"
     ]
    }
   ],
   "source": [
    "numberOfRows, numberOfColumns = personalityList.shape\n",
    "print(f'Number of texts = {numberOfRows}  and Personality Groups = {numberOfColumns} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now I am going to further process the dataset in order to remove words that are not relevant. I will do this by vectorizing the texts based on a certain margin. The margin that I have decided is between 12% to 75%. Any words in the dataset that do not occur as frequent as this percentage will be removed so only the releavnt words will be in place. This is also known as feature engineering. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CountVectorizer :\n",
      "A few of the features:\n",
      "[(0, '10'), (1, '100'), (2, '20'), (3, 'ability'), (4, 'able')]\n",
      "\\With TFIDF :\n",
      "Now the dataset size is as below\n",
      "(8675, 755)\n"
     ]
    }
   ],
   "source": [
    "#Initializing a variable names CVZ (count Vectorizer)\n",
    "CVZ = CountVectorizer(analyzer=\"word\", \n",
    "                             max_features=1000,  \n",
    "                             max_df=0.75,\n",
    "                             min_df=0.12) \n",
    "\n",
    "print(\"Using CountVectorizer :\")\n",
    "number_of_X = CVZ.fit_transform(textsList)\n",
    "\n",
    "names_of_features = list(enumerate(CVZ.get_feature_names()))\n",
    "print(\"A few of the features:\")\n",
    "print(names_of_features[0:5])\n",
    "\n",
    "tfi = TfidfTransformer()\n",
    "\n",
    "print(\"\\With TFIDF :\")\n",
    "\n",
    "print(\"Now the dataset size is as below\")\n",
    "tfi_X =  tfi.fit_transform(number_of_X).toarray()\n",
    "print(tfi_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting into X and Y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IE: Introversion (I) / Extroversion (E)\n",
      "NS: Intuition (N) / Sensing (S)\n",
      "FT: Feeling (F) / Thinking (T)\n",
      "JP: Judging (J) / Perceiving (P)\n"
     ]
    }
   ],
   "source": [
    "personality_type = [ \"IE: Introversion (I) / Extroversion (E)\", \"NS: Intuition (N) / Sensing (S)\", \n",
    "                   \"FT: Feeling (F) / Thinking (T)\", \"JP: Judging (J) / Perceiving (P)\"  ]\n",
    "\n",
    "for x in range(len(personality_type)):\n",
    "    print(personality_type[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and Evaluating Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Initialising the posts that are in the TFI-DF format to a variable A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = tfi_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In order to improve the accuracy rates, I have also implemented a method in which I will train each personality type seperately as you can see below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IE: Introversion (I) / Extroversion (E) The Accuracy is: 79.71%\n",
      "NS: Intuition (N) / Sensing (S) The Accuracy is: 86.31%\n",
      "FT: Feeling (F) / Thinking (T) The Accuracy is: 80.34%\n",
      "JP: Judging (J) / Perceiving (P) The Accuracy is: 74.15%\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(personality_type)):\n",
    "    \n",
    "    M = personalityList[:,i]\n",
    "\n",
    "    # Now we will split the data into test and train according to the 70-30% ratio\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(A, M, test_size=0.33, random_state=7)\n",
    "\n",
    "    TypeModel = RandomForestClassifier()\n",
    "    TypeModel.fit(X_train, y_train)\n",
    "\n",
    "    predictY= TypeModel.predict(X_test)\n",
    "     \n",
    "    results = [round(x) for x in predictY]\n",
    "    scores = accuracy_score(y_test, results)\n",
    "    \n",
    "    print(\"%s The Accuracy is: %.2f%%\" % (personality_type[i], scores * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IE: Introversion (I) / Extroversion (E) The Accuracy is: 85.99%\n",
      "NS: Intuition (N) / Sensing (S) The Accuracy is: 89.91%\n",
      "FT: Feeling (F) / Thinking (T) The Accuracy is: 81.49%\n",
      "JP: Judging (J) / Perceiving (P) The Accuracy is: 78.45%\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(personality_type)):\n",
    "    \n",
    "    M = personalityList[:,i]\n",
    "\n",
    "    # Now we will split the data into test and train according to the 70-30% ratio\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(A, M, test_size=0.33, random_state=7)\n",
    "\n",
    "    TypeModel = XGBClassifier()\n",
    "    TypeModel.fit(X_train, y_train)\n",
    "\n",
    "    predictY= TypeModel.predict(X_test)\n",
    "    \n",
    "    # Checking against the results and the accuracies \n",
    "    results = [round(x) for x in predictY]\n",
    "    scores = accuracy_score(y_test, results)\n",
    "    \n",
    "    print(\"%s The Accuracy is: %.2f%%\" % (personality_type[i], scores * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IE: Introversion (I) / Extroversion (E) The Accuracy is: 85.30%\n",
      "NS: Intuition (N) / Sensing (S) The Accuracy is: 88.47%\n",
      "FT: Feeling (F) / Thinking (T) The Accuracy is: 84.00%\n",
      "JP: Judging (J) / Perceiving (P) The Accuracy is: 78.76%\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(personality_type)):\n",
    "    \n",
    "    M = personalityList[:,i]\n",
    "\n",
    "    # Now we will split the data into test and train according to the 70-30% ratio\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(A, M, test_size=0.33, random_state=7)\n",
    "\n",
    "    TypeModel = LogisticRegression()\n",
    "    TypeModel.fit(X_train, y_train)\n",
    "\n",
    "    predictY= TypeModel.predict(X_test)\n",
    "    \n",
    "    # Checking against the results and the accuracies \n",
    "    results = [round(x) for x in predictY] \n",
    "    scores = accuracy_score(y_test, results)\n",
    "    \n",
    "    print(\"%s The Accuracy is: %.2f%%\" % (personality_type[i], scores * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IE: Introversion (I) / Extroversion (E) The Accuracy is: 85.89%\n",
      "NS: Intuition (N) / Sensing (S) The Accuracy is: 88.47%\n",
      "FT: Feeling (F) / Thinking (T) The Accuracy is: 83.90%\n",
      "JP: Judging (J) / Perceiving (P) The Accuracy is: 78.83%\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(personality_type)):\n",
    "    \n",
    "    M = personalityList[:,i]\n",
    "\n",
    "    # Now we will split the data into test and train according to my second implementation ratio of 70-30\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(A, M, test_size=0.33, random_state=7)\n",
    "\n",
    "    TypeModel = SVC(random_state = 1)\n",
    "    TypeModel.fit(X_train, y_train)\n",
    "\n",
    "    predictY= TypeModel.predict(X_test)\n",
    "    \n",
    "    # Checking against the results and the accuracies \n",
    "    results = [round(x) for x in predictY]\n",
    "    scores = accuracy_score(y_test, results)\n",
    "    \n",
    "    print(\"%s The Accuracy is: %.2f%%\" % (personality_type[i], scores * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We notice that XGBoost gives me the best results and have improved alot from the baseline models. \n",
    "\n",
    "Now I will try to implement hyperparameter tuning to increase the accuracies even more. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IE: Introversion (I) / Extroversion (E) The Accuracy is: 84.70%\n",
      "NS: Intuition (N) / Sensing (S) The Accuracy is: 89.73%\n",
      "FT: Feeling (F) / Thinking (T) The Accuracy is: 82.89%\n",
      "JP: Judging (J) / Perceiving (P) The Accuracy is: 79.74%\n"
     ]
    }
   ],
   "source": [
    "hyperpar = {}\n",
    "hyperpar['n_estimators'] = 199\n",
    "hyperpar['max_depth'] = 3\n",
    "hyperpar['nthread'] = 7\n",
    "hyperpar['learning_rate'] = 0.1\n",
    "\n",
    "\n",
    "for i in range(len(personality_type)):\n",
    "    M = personalityList[:,i]\n",
    "\n",
    "    # Splitting the dataset into the relevant train and test data following the same 70 30 ratio \n",
    "    seed = 13\n",
    "    test_size = 0.33\n",
    "    X_train, X_test, y_train, y_test = train_test_split(A, M, test_size=test_size, random_state=seed)\n",
    "    TypeModel = XGBClassifier(**hyperpar)\n",
    "    TypeModel.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    # Initialising the prediction values now \n",
    "    \n",
    "    predictY = TypeModel.predict(X_test)\n",
    "     # Checking against the results and the accuracies \n",
    "    results = [round(x) for x in predictY]\n",
    "    scores = accuracy_score(y_test, results)\n",
    "    print(\"%s The Accuracy is: %.2f%%\" % (personality_type[i], scores * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the program with a sample short essay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "testPost = \"\"\"At St. Albans, especially in our later years, we are given the freedom to choose from a \n",
    "vast array of classes. Using this freedom, I have selected classes which have personal significance to me, \n",
    "regardless of difficulty or appearance on my transcript. However, from these classes, one holds an extraordinary \n",
    "amount of value to me. This course is A.P. (Omnibus) History, a combination of American and European history. \n",
    "There are several reasons for my great interest in this class. First, I am fascinated by the cyclical nature \n",
    "of the past... I see these recurring political, economic, and social trends as a means of looking forward into \n",
    "the future, while allowing us to avoid the mistakes of the past. Second, history teaches many lessons about \n",
    "the nature of human behavior, both past and present, providing insight into the actions, desires, and aspirations \n",
    "of those around me. Finally, it lays a solid foundation for several disciplines, including political science, \n",
    "economics, and international relations, three fields of great interest to me.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = pd.DataFrame(data={'type': ['ENTP'], 'posts': [testPost]})\n",
    "\n",
    "testPost, dummy  = text_preprocessing(testing, remove_stop_words=True, remove_mbti_profiles=True)\n",
    "cnti= CVZ.transform(testPost)\n",
    "tfid =  tfi.transform(cnti).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperpar = {}\n",
    "hyperpar['n_estimators'] = 100\n",
    "hyperpar['max_depth'] = 3\n",
    "hyperpar['nthread'] = 7\n",
    "hyperpar['learning_rate'] = 0.1\n",
    "\n",
    "#XGBoost model for MBTI dataset\n",
    "MyModelsPrediction = []\n",
    "\n",
    "for i in range(len(personality_type)):\n",
    "    M = personalityList[:,i]\n",
    "\n",
    "    # Splitting the dataset into the relevant train and test data following the same 70 30 ratio \n",
    "    seed = 13\n",
    "    test_size = 0.33\n",
    "    X_train, X_test, y_train, y_test = train_test_split(A, M, test_size=test_size, random_state=seed)\n",
    "    TypeModel = XGBClassifier(**hyperpar)\n",
    "    TypeModel.fit(X_train, y_train)\n",
    "    \n",
    "    predictY = TypeModel.predict(tfid)\n",
    "    MyModelsPrediction.append(predictY[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Prediction Is  JFES\n"
     ]
    }
   ],
   "source": [
    "print(\"The Prediction Is \", convertBack(MyModelsPrediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References:\n",
    "\n",
    "Towler, D. A. (n.d.). Why taking a personality test helps your professional development: CQ net. CQ Net - Management skills for everyone! Retrieved June 26, 2022, from https://www.ckju.net/en/blog/why-taking-personality-test-helps-your-professional-development \n",
    "\n",
    "Kamalesh, M. D., & B, B. (2022, March 11). Personality prediction model for social media using machine learning technique. Computers and Electrical Engineering. Retrieved June 26, 2022, from https://www.sciencedirect.com/science/article/abs/pii/S0045790622001446 \n",
    "\n",
    "Tandera, T., Hendro, D., Suhartono, R., & Wongso, Y. L. (2017, October 13). Personality prediction system from Facebook users. Procedia Computer Science. Retrieved June 26, 2022, from https://www.sciencedirect.com/science/article/pii/S1877050917320537 \n",
    "\n",
    "Christian, H., Suhartono, D., Chowanda, A., & Zamli, K. Z. (2021, May 17). Text based personality prediction from multiple social media data sources using pre-trained language model and model averaging - journal of big data. SpringerOpen. Retrieved June 26, 2022, from https://journalofbigdata.springeropen.com/articles/10.1186/s40537-021-00459-1 \n",
    "\n",
    "Overview of personality prediction project using ML. GeeksforGeeks. (2020, September 5). Retrieved June 26, 2022, from https://www.geeksforgeeks.org/overview-of-personality-prediction-project-using-ml/ \n",
    "\n",
    "M, T., & K, M. A. (2021, June 4). Comparative study of personality prediction from social media by using machine learning and Deep Learning Method. International Journal of Engineering Research & Technology. Retrieved June 26, 2022, from https://www.ijert.org/comparative-study-of-personality-prediction-from-social-media-by-using-machine-learning-and-deep-learning-method \n",
    "\n",
    "Cherry, K. (2020, May 4). Why learning more about your personality type can benefit your life. Verywell Mind. Retrieved June 26, 2022, from https://www.verywellmind.com/reasons-to-learn-more-about-your-personality-type-4099388 \n",
    "\n",
    "The advantages and disadvantages of personality tests. mettl. (2021, August 12). Retrieved June 26, 2022, from https://blog.mettl.com/advantages-disadvantages-of-personality-tests/ \n",
    "\n",
    "Yutuk, K. (2022, June 2). Pros and cons of personality tests. Aptitude.ph. Retrieved June 26, 2022, from https://www.aptitude.ph/benefits-of-personality-testing-for-companies/ \n",
    "\n",
    "f83lfV7Yd43Z. (2022, January 14). Can personality testing benefit your company? MidwestHR. Retrieved June 26, 2022, from https://www.midwesthr.com/personality-testing-benefits \n",
    "\n",
    "What is Project Design in project management? Wrike. (n.d.). Retrieved June 26, 2022, from https://www.wrike.com/project-management-guide/faq/what-is-project-design-in-project-management/ \n",
    "\n",
    "Scavetta, A. (2022, June 21). The best way to make a work plan. ProjectManager. Retrieved June 26, 2022, from https://www.projectmanager.com/blog/make-work-plan \n",
    "\n",
    "Project structure. Project Structure - an overview | ScienceDirect Topics. (n.d.). Retrieved June 26, 2022, from https://www.sciencedirect.com/topics/computer-science/project-structure#:~:text=A%20project%20structure%20provides%20the,of%20the%20local%20development%20landscape. \n",
    "\n",
    "Rajshreev. 2021. MBTI personality predictor using machine learning. (April 2021). Retrieved September 5, 2022 from https://www.kaggle.com/code/rajshreev/mbti-personality-predictor-using-machine-learning/notebook "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
